{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKTI481IlRXj"
      },
      "source": [
        "# 배경 제거 Application\n",
        "\n",
        "Colab 환경에서 배경 제거 애플리케이션을 만들어봅시다. 애플리케이션 사용자의 유스케이스는 아래와 같습니다.\n",
        "\n",
        "- 사용자는 이미지 파일을 업로드할 수 있다.\n",
        "- 사용자는 이미지에서 원하는 객체 클릭한다.\n",
        "- 사용자는 배경 제거 이미지의 결과를 확인하고 다운로드 받을 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiTJbGiwlRXk"
      },
      "source": [
        "## 패키지 및 예제 데이터 다운로드하기\n",
        "python package들을 설치합니다. 예제로 사용할 이미지들도 다운로드 받습니다. Colab에서 실행하지 않는 경우 이 셀은 실행하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "edGyc5vClRXk",
        "outputId": "6c921a25-168f-491e-cf6b-c13b9a7bef1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-02 12:32:55--  https://raw.githubusercontent.com/mentor1023/dl_apps/main/segmentation/requirements-colab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147 [text/plain]\n",
            "Saving to: ‘requirements-colab.txt.1’\n",
            "\n",
            "\rrequirements-colab.   0%[                    ]       0  --.-KB/s               \rrequirements-colab. 100%[===================>]     147  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-02 12:32:55 (11.6 MB/s) - ‘requirements-colab.txt.1’ saved [147/147]\n",
            "\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git (from -r requirements-colab.txt (line 2))\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-zg99tbfa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-zg99tbfa\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycocotools==2.0.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 3)) (2.0.6)\n",
            "Requirement already satisfied: gradio==3.40.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 6)) (3.40.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (23.2.1)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.11.2)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.115.5)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: gradio-client>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.26.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.3.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (10.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.32.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (11.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.4.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.16.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.66.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (8.1.7)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.41.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.2.2)\n",
            "mkdir: cannot create directory ‘examples’: File exists\n",
            "--2024-12-02 12:33:00--  https://github.com/mentor1023/dl_apps/raw/main/segmentation/examples/dog.jpg\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mentor1023/dl_apps/main/segmentation/examples/dog.jpg [following]\n",
            "--2024-12-02 12:33:00--  https://raw.githubusercontent.com/mentor1023/dl_apps/main/segmentation/examples/dog.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 221810 (217K) [image/jpeg]\n",
            "Saving to: ‘dog.jpg.1’\n",
            "\n",
            "dog.jpg.1           100%[===================>] 216.61K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-02 12:33:01 (7.38 MB/s) - ‘dog.jpg.1’ saved [221810/221810]\n",
            "\n",
            "--2024-12-02 12:33:01--  https://github.com/mentor1023/dl_apps/raw/main/segmentation/examples/mannequin.jpg\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mentor1023/dl_apps/main/segmentation/examples/mannequin.jpg [following]\n",
            "--2024-12-02 12:33:01--  https://raw.githubusercontent.com/mentor1023/dl_apps/main/segmentation/examples/mannequin.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 478925 (468K) [image/jpeg]\n",
            "Saving to: ‘mannequin.jpg.1’\n",
            "\n",
            "mannequin.jpg.1     100%[===================>] 467.70K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-02 12:33:01 (14.8 MB/s) - ‘mannequin.jpg.1’ saved [478925/478925]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mentor1023/dl_apps/main/segmentation/requirements-colab.txt\n",
        "!pip install -r requirements-colab.txt\n",
        "\n",
        "!mkdir examples\n",
        "!cd examples && wget https://github.com/mentor1023/dl_apps/raw/main/segmentation/examples/dog.jpg\n",
        "!cd examples && wget https://github.com/mentor1023/dl_apps/raw/main/segmentation/examples/mannequin.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBMNtFdHlRXl"
      },
      "source": [
        "## 패키지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "al5RTe62lRXl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib\n",
        "from typing import Tuple\n",
        "\n",
        "import cv2\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from segment_anything import SamPredictor, sam_model_registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGnoU0nilRXm"
      },
      "source": [
        "## 애플리케이션 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qu0N7lerlRXm"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
        "    with gr.Row():\n",
        "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
        "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=600)\n",
        "        output_img = gr.Image(label=\"Output image\", height=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g02IWmMQlRXm",
        "outputId": "70ad30b4-4723-4623-ce8f-d5114d1325ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a6e35b165742fd33ec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bHLzV9LtlRXm",
        "outputId": "5d35f91c-3905-452c-e80e-d9481804749a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BOZ__1lRXm"
      },
      "source": [
        "## 마우스 클릭 이벤트 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FylsRUzOlRXm"
      },
      "outputs": [],
      "source": [
        "def get_coords(evt: gr.SelectData):\n",
        "    return evt.index[0], evt.index[1]\n",
        "\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
        "    with gr.Row():\n",
        "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
        "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=600)\n",
        "        output_img = gr.Image(label=\"Output image\", height=600)\n",
        "\n",
        "    input_img.select(get_coords, None, [coord_x, coord_y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ABiCmlGhlRXn",
        "outputId": "b0fd5db7-0108-4387-b74f-4065b1685d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://45ee2dd3d281c24500.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1rBo49HllRXn",
        "outputId": "dc495be6-639f-44e0-e07b-a659a5f87041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p90WgDNlRXn"
      },
      "source": [
        "## SAM 추론기 클래스 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xZg7b6uglRXn"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_PATH = os.path.join(\"checkpoint\")\n",
        "CHECKPOINT_NAME = \"sam_vit_h_4b8939.pth\"\n",
        "CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_HjWb196lRXn"
      },
      "outputs": [],
      "source": [
        "class SAMInferencer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        checkpoint_path: str,\n",
        "        checkpoint_name: str,\n",
        "        checkpoint_url: str,\n",
        "        model_type: str,\n",
        "        device: torch.device,\n",
        "    ):\n",
        "        print(\"[INFO] Initailize inferencer\")\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            os.makedirs(checkpoint_path, exist_ok=True)\n",
        "        checkpoint = os.path.join(checkpoint_path, checkpoint_name)\n",
        "        if not os.path.exists(checkpoint):\n",
        "            urllib.request.urlretrieve(checkpoint_url, checkpoint)\n",
        "        sam = sam_model_registry[model_type](checkpoint=checkpoint).to(device)\n",
        "        self.predictor = SamPredictor(sam)\n",
        "\n",
        "    def inference(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        point_coords: np.ndarray,\n",
        "        points_labels: np.ndarray,\n",
        "    ) -> np.ndarray:\n",
        "        self.predictor.set_image(image)\n",
        "        masks, scores, _ = self.predictor.predict(point_coords, points_labels)\n",
        "        mask, _ = self.select_mask(masks, scores)\n",
        "        return mask\n",
        "\n",
        "    def select_mask(\n",
        "        self, masks: np.ndarray, scores: np.ndarray\n",
        "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        # Determine if we should return the multiclick mask or not from the number of points.\n",
        "        # The reweighting is used to avoid control flow.\n",
        "        # Reference: https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/utils/onnx.py#L92-L105\n",
        "        score_reweight = np.array([-1000] + [0] * 2)\n",
        "        score = scores + score_reweight\n",
        "        best_idx = np.argmax(score)\n",
        "        selected_mask = np.expand_dims(masks[best_idx, :, :], axis=-1)\n",
        "        selected_score = np.expand_dims(scores[best_idx], axis=0)\n",
        "        return selected_mask, selected_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vffOiWEWlRXn",
        "outputId": "98198a28-d5c9-4e1a-d5a2-8f7a757bfa08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Initailize inferencer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(f)\n"
          ]
        }
      ],
      "source": [
        "inferencer = SAMInferencer(\n",
        "    CHECKPOINT_PATH, CHECKPOINT_NAME, CHECKPOINT_URL, \"vit_h\", DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdto9mbalRXn"
      },
      "source": [
        "## 추론 및 배경 제거 후처리 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XoKDi6OslRXn"
      },
      "outputs": [],
      "source": [
        "def extract_object(image: np.ndarray, point_x: int, point_y: int):\n",
        "    point_coords = np.array([[point_x, point_y]])\n",
        "    point_label = np.array([1])\n",
        "\n",
        "    # Get mask\n",
        "    mask = inferencer.inference(image, point_coords, point_label)\n",
        "\n",
        "    # Extract object and remove background\n",
        "    # Postprocess mask\n",
        "    mask = (mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Remove background\n",
        "    result_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    # Convert to rgba channel\n",
        "    bgr_channel = result_image[..., :3]  # BGR 채널 분리\n",
        "    alpha_channel = np.where(bgr_channel[..., 0] == 0, 0, 255).astype(np.uint8)\n",
        "    result_image = np.dstack((bgr_channel, alpha_channel))  # BGRA 이미지 생성\n",
        "\n",
        "    return result_image\n",
        "\n",
        "\n",
        "def extract_object_by_event(image: np.ndarray, evt: gr.SelectData):\n",
        "    click_x, click_y = evt.index\n",
        "\n",
        "    return extract_object(image, click_x, click_y)\n",
        "\n",
        "\n",
        "def get_coords(evt: gr.SelectData):\n",
        "    return evt.index[0], evt.index[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x89mm_bwlRXn"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
        "    with gr.Row():\n",
        "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
        "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=600)\n",
        "        output_img = gr.Image(label=\"Output image\", height=600)\n",
        "\n",
        "    input_img.select(extract_object_by_event, [input_img], [output_img])\n",
        "    input_img.select(get_coords, None, [coord_x, coord_y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BaCeGW6-lRXn",
        "outputId": "3b98129e-ceb8-4ba4-d7a3-24f97fd7c813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://435090d43e046ea831.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Aq9PLUBdlRXn",
        "outputId": "84aec239-c941-49f6-9478-1e7e16409668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E81u8UflRXn"
      },
      "source": [
        "## 최종 App 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "raI9ccjjlRXo",
        "outputId": "e172f4af-0ccb-42d2-fd12-bda16fe0edfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Initailize inferencer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "IMPORTANT: You are using gradio version 3.40.0, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://98c5867d2d7f9c8596.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Implement inferencer\n",
        "CHECKPOINT_PATH = os.path.join(\"checkpoint\")\n",
        "CHECKPOINT_NAME = \"sam_vit_h_4b8939.pth\"\n",
        "CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
        "MODEL_TYPE = \"default\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class SAMInferencer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        checkpoint_path: str,\n",
        "        checkpoint_name: str,\n",
        "        checkpoint_url: str,\n",
        "        model_type: str,\n",
        "        device: torch.device,\n",
        "    ):\n",
        "        print(\"[INFO] Initailize inferencer\")\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            os.makedirs(checkpoint_path, exist_ok=True)\n",
        "        checkpoint = os.path.join(checkpoint_path, checkpoint_name)\n",
        "        if not os.path.exists(checkpoint):\n",
        "            urllib.request.urlretrieve(checkpoint_url, checkpoint)\n",
        "        sam = sam_model_registry[model_type](checkpoint=checkpoint).to(device)\n",
        "        self.predictor = SamPredictor(sam)\n",
        "\n",
        "    def inference(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        point_coords: np.ndarray,\n",
        "        points_labels: np.ndarray,\n",
        "    ) -> np.ndarray:\n",
        "        self.predictor.set_image(image)\n",
        "        masks, scores, _ = self.predictor.predict(point_coords, points_labels)\n",
        "        mask, _ = self.select_mask(masks, scores)\n",
        "        return mask\n",
        "\n",
        "    def select_mask(\n",
        "        self, masks: np.ndarray, scores: np.ndarray\n",
        "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        # Determine if we should return the multiclick mask or not from the number of points.\n",
        "        # The reweighting is used to avoid control flow.\n",
        "        # Reference: https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/utils/onnx.py#L92-L105\n",
        "        score_reweight = np.array([-1000] + [0] * 2)\n",
        "        score = scores + score_reweight\n",
        "        best_idx = np.argmax(score)\n",
        "        selected_mask = np.expand_dims(masks[best_idx, :, :], axis=-1)\n",
        "        selected_score = np.expand_dims(scores[best_idx], axis=0)\n",
        "        return selected_mask, selected_score\n",
        "\n",
        "\n",
        "inferencer = SAMInferencer(\n",
        "    CHECKPOINT_PATH, CHECKPOINT_NAME, CHECKPOINT_URL, MODEL_TYPE, DEVICE\n",
        ")\n",
        "\n",
        "# Implement event function\n",
        "def extract_object(image: np.ndarray, point_x: int, point_y: int):\n",
        "    point_coords = np.array([[point_x, point_y], [0, 0]])\n",
        "    point_label = np.array([1, -1])\n",
        "\n",
        "    # Get mask\n",
        "    mask = inferencer.inference(image, point_coords, point_label)\n",
        "\n",
        "    # Extract object and remove background\n",
        "    # Postprocess mask\n",
        "    mask = (mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Remove background\n",
        "    result_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    # Convert to rgba channel\n",
        "    bgr_channel = result_image[..., :3]  # BGR 채널 분리\n",
        "    alpha_channel = np.where(bgr_channel[..., 0] == 0, 0, 255).astype(np.uint8)\n",
        "    result_image = np.dstack((bgr_channel, alpha_channel))  # BGRA 이미지 생성\n",
        "\n",
        "    return result_image\n",
        "\n",
        "\n",
        "def extract_object_by_event(image: np.ndarray, evt: gr.SelectData):\n",
        "    click_x, click_y = evt.index\n",
        "\n",
        "    return extract_object(image, click_x, click_y)\n",
        "\n",
        "\n",
        "def get_coords(evt: gr.SelectData):\n",
        "    return evt.index[0], evt.index[1]\n",
        "\n",
        "\n",
        "# Implement app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
        "    with gr.Row():\n",
        "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
        "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=600)\n",
        "        output_img = gr.Image(label=\"Output image\", height=600)\n",
        "\n",
        "    input_img.select(get_coords, None, [coord_x, coord_y])\n",
        "    input_img.select(extract_object_by_event, [input_img], output_img)\n",
        "\n",
        "    gr.Markdown(\"## Image Examples\")\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [os.path.join(os.getcwd(), \"examples/dog.jpg\"), 1013, 786],\n",
        "            [os.path.join(os.getcwd(), \"examples/mannequin.jpg\"), 1720, 230],\n",
        "        ],\n",
        "        inputs=[input_img, coord_x, coord_y],\n",
        "        outputs=output_img,\n",
        "        fn=extract_object,\n",
        "        run_on_click=True,\n",
        "    )\n",
        "\n",
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RkiC16wQlRXo",
        "outputId": "d2486d5a-09a2-4c8b-ebe7-b2a8e0369583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39npOh_RlRXo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}