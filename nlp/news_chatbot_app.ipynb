{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ECiJVuTtuGM"
      },
      "source": [
        "# 뉴스 기사 탐색 챗봇 Application\n",
        "\n",
        "Colab 환경에서 뉴스 기사 탐색 챗봇 애플리케이션을 만들어봅시다. 애플리케이션 사용자의 유스케이스는 아래와 같습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5iAnk8KtuGN"
      },
      "source": [
        "## 패키지 및 예제 데이터 다운로드하기\n",
        "예제를 실행시키기 위해 python package들을 설치합니다. Colab에서 실행하지 않는 경우 이 셀은 실행하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYZ9wbbotuGO"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mentor1023/dl_apps/main/nlp/requirements-colab.txt\n",
        "!pip install -r requirements-colab.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mentor1023/dl_apps/main/nlp/requirements-colab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4DOMjh0uGHd",
        "outputId": "e91176f3-2ee8-471e-a41f-c9fecf72cdf6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-04 08:10:48--  https://raw.githubusercontent.com/mentor1023/dl_apps/main/nlp/requirements-colab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114 [text/plain]\n",
            "Saving to: ‘requirements-colab.txt’\n",
            "\n",
            "requirements-colab. 100%[===================>]     114  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-04 08:10:49 (1.66 MB/s) - ‘requirements-colab.txt’ saved [114/114]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-colab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_clETXouF9_",
        "outputId": "59bc77ee-0de4-4666-8d05-7c5d07409599"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.31.0 (from -r requirements-colab.txt (line 1))\n",
            "  Downloading openai-1.31.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting beautifulsoup4==4.12.2 (from -r requirements-colab.txt (line 2))\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting gradio==3.40.0 (from -r requirements-colab.txt (line 5))\n",
            "  Downloading gradio-3.40.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.0->-r requirements-colab.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.2->-r requirements-colab.txt (line 2)) (2.6)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.11.2)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client>=0.4.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.26.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.0.0)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.8.0)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydub (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.32.3)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.4.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.31.0->-r requirements-colab.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (8.1.7)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->gradio==3.40.0->-r requirements-colab.txt (line 5))\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.16.0)\n",
            "Downloading openai-1.31.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.40.0-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading gradio_client-1.5.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, semantic-version, python-multipart, pillow, markupsafe, markdown-it-py, ffmpy, beautifulsoup4, aiofiles, starlette, mdit-py-plugins, openai, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.12.3\n",
            "    Uninstalling beautifulsoup4-4.12.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.12.3\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.2\n",
            "    Uninstalling mdit-py-plugins-0.4.2:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.2\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.4\n",
            "    Uninstalling openai-1.54.4:\n",
            "      Successfully uninstalled openai-1.54.4\n",
            "Successfully installed aiofiles-23.2.1 beautifulsoup4-4.12.2 fastapi-0.115.6 ffmpy-0.4.0 gradio-3.40.0 gradio-client-1.5.0 markdown-it-py-2.2.0 markupsafe-2.1.5 mdit-py-plugins-0.3.3 openai-1.31.0 pillow-10.4.0 pydub-0.25.1 python-multipart-0.0.19 semantic-version-2.10.0 starlette-0.41.3 uvicorn-0.32.1 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "ada4b636b27e42148112e55abf37c989"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdZwowQDtuGP"
      },
      "source": [
        "## 패키지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1hDn0drltuGP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Any, Callable, Dict, List, Tuple\n",
        "import os\n",
        "\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z63tdk3CtuGP"
      },
      "source": [
        "## 챗봇 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qJz8gFAVtuGQ"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        ## Chat\n",
        "        얻고 싶은 정보에 대해 질문해보세요.\n",
        "        \"\"\"\n",
        "    )\n",
        "    chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "    prompt = gr.Textbox(label=\"Input prompt\")\n",
        "    clear = gr.ClearButton([prompt, chatbot])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oudV-oVmtuGQ",
        "outputId": "77ebda14-5568-4706-ad66-298f20b88158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e4383c327f9200d2d0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhnWkaDCtuGQ",
        "outputId": "20c82a0f-e7e2-44ee-b5e3-9c1d1b793797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Xme59-tuGQ"
      },
      "source": [
        "## GPT API로 기본적인 챗봇 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xPOqDWXetuGQ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"본인의 OpenAI API Key 입력\""
      ],
      "metadata": {
        "id": "AnTFp69gxmCh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ve7NT25mtuGQ"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "model = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vPhVLANltuGQ"
      },
      "outputs": [],
      "source": [
        "def respond(prompt: str, chat_history: List[str]) -> Tuple[str, List[str]]:\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    res = client.chat.completions.create(model=model, messages=messages)\n",
        "    answer = res.choices[0].message.content\n",
        "\n",
        "    chat_history.append((prompt, answer))\n",
        "\n",
        "    return \"\", chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t4KSiL2ctuGR"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        ## Chat\n",
        "        얻고 싶은 정보에 대해 질문해보세요.\n",
        "        \"\"\"\n",
        "    )\n",
        "    chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "    prompt = gr.Textbox(label=\"Input prompt\")\n",
        "    clear = gr.ClearButton([prompt, chatbot])\n",
        "\n",
        "    prompt.submit(respond, [prompt, chatbot], [prompt, chatbot])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92yl4EVNtuGR",
        "outputId": "781cfb5a-08e1-443e-9223-cdc16e7f402b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://2b79d78e3389a0866e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6DiUigxtuGR",
        "outputId": "a7a53811-66d6-4aca-820d-50bdd5dcd2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iljgWF8WtuGR"
      },
      "source": [
        "## News API를 활용해 뉴스 기사 정보 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wwp6-lptuGR"
      },
      "outputs": [],
      "source": [
        "os.environ[\"NEWS_API_KEY\"] = \"<NEWS_API_KEY>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMbZFVsktuGR"
      },
      "outputs": [],
      "source": [
        "endpoint = \"https://newsapi.org/v2/everything\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv3ZQJpztuGR"
      },
      "outputs": [],
      "source": [
        "headers = {\"x-api-key\": os.environ[\"NEWS_API_KEY\"]}\n",
        "params = {\n",
        "    \"sources\": \"cnn\",\n",
        "    \"language\": \"en\",\n",
        "    \"q\": \"Tesla\",\n",
        "    \"sortBy\": \"publishedAt\"\n",
        "}\n",
        "\n",
        "# Fetch from newsapi.org\n",
        "response = requests.get(endpoint, params=params, headers=headers)\n",
        "data = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxwFSoNVtuGR"
      },
      "outputs": [],
      "source": [
        "data[\"articles\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8buxaq6EtuGR"
      },
      "outputs": [],
      "source": [
        "class NewsApiClient:\n",
        "    def __init__(self):\n",
        "        self.news_api_key = os.environ[\"NEWS_API_KEY\"]\n",
        "        self.max_num_articles = 5\n",
        "\n",
        "    def get_articles(\n",
        "        self,\n",
        "        query: str = None,\n",
        "        from_date: str = None,\n",
        "        to_date: str = None,\n",
        "        sort_by: str = None,\n",
        "    ) -> str:\n",
        "        \"\"\"Retrieve articles from newsapi.org (API key required)\"\"\"\n",
        "        endpoint = \"https://newsapi.org/v2/everything\"\n",
        "        headers = {\"x-api-key\": self.news_api_key}\n",
        "        params = {\n",
        "            \"sortBy\": \"publishedAt\",\n",
        "            \"sources\": \"cnn\",\n",
        "            \"language\": \"en\",\n",
        "        }\n",
        "\n",
        "        if query is not None:\n",
        "            params[\"q\"] = query\n",
        "        if from_date is not None:\n",
        "            params[\"from\"] = from_date\n",
        "        if to_date is not None:\n",
        "            params[\"to\"] = to_date\n",
        "        if sort_by is not None:\n",
        "            params[\"sortBy\"] = sort_by\n",
        "\n",
        "        # Fetch from newsapi.org\n",
        "        # reference: https://newsapi.org/docs/endpoints/top-headlines\n",
        "        response = requests.get(endpoint, params=params, headers=headers)\n",
        "        data = response.json()\n",
        "\n",
        "        if data[\"status\"] == \"ok\":\n",
        "            print(\n",
        "                f\"Processing {data['totalResults']} articles from newsapi.org. \"\n",
        "                + f\"Max number is {self.max_num_articles}.\"\n",
        "            )\n",
        "            return json.dumps(\n",
        "                data[\"articles\"][: min(self.max_num_articles, len(data[\"articles\"]))]\n",
        "            )\n",
        "        else:\n",
        "            print(\"Request failed with message:\", data[\"message\"])\n",
        "            return \"No articles found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYTKZoW8tuGR"
      },
      "outputs": [],
      "source": [
        "news_api_client = NewsApiClient()\n",
        "news_api_client.get_articles(query=\"Tesla\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCKKsuwdtuGR"
      },
      "source": [
        "## 함수 호출 기능을 활용한 뉴스 기사 탐색 챗봇 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd-6WMXrtuGS"
      },
      "outputs": [],
      "source": [
        "signature_get_articles = {\n",
        "    \"name\": \"get_articles\",\n",
        "    \"description\": \"Get news articles\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Freeform keywords or a phrase to search for.\",\n",
        "            },\n",
        "            \"from_date\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A date and optional time for the oldest article allowed. This should be in ISO 8601 format\",\n",
        "            },\n",
        "            \"to_date\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A date and optional time for the newest article allowed. This should be in ISO 8601 format\",\n",
        "            },\n",
        "            \"sort_by\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The order to sort the articles in\",\n",
        "                \"enum\": [\"relevancy\", \"popularity\", \"publishedAt\"],\n",
        "            },\n",
        "        },\n",
        "        \"required\": [],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCow6FyDtuGS"
      },
      "outputs": [],
      "source": [
        "class GPTClient:\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "        self.model = \"gpt-3.5-turbo\"\n",
        "\n",
        "    def get_args_for_function_call(\n",
        "        self, messages: List[Dict[str, str]], function_signatures: List[Dict[str, Any]]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        If there is information for function in messages, get argument from messages.\n",
        "        Otherwise get simple GPT response.\n",
        "        \"\"\"\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            functions=function_signatures,\n",
        "        )\n",
        "        return response.choices[0].message\n",
        "\n",
        "    def request_with_function_call(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        function: Callable,\n",
        "        function_call_resp,\n",
        "        prompt: str = \"\",\n",
        "    ) -> str:\n",
        "        function_name = function_call_resp.function_call.name\n",
        "\n",
        "        if prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": prompt})\n",
        "\n",
        "        # Run external function\n",
        "        kwargs = json.loads(function_call_resp.function_call.arguments)\n",
        "        function_result = function(**kwargs)\n",
        "\n",
        "        # Append message\n",
        "        messages.append(function_call_resp)\n",
        "        messages.append(\n",
        "            {\"role\": \"function\", \"name\": function_name, \"content\": function_result}\n",
        "        )\n",
        "\n",
        "        # GPT inference include function result\n",
        "        res = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "        )\n",
        "        return res.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0YzU4RRtuGS"
      },
      "outputs": [],
      "source": [
        "gpt_client = GPTClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziOZ9v3LtuGS"
      },
      "outputs": [],
      "source": [
        "def respond(prompt: str, chat_history: List[str]) -> Tuple[str, List[str]]:\n",
        "    # Get args from prompt\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    args_resp = gpt_client.get_args_for_function_call(messages, [signature_get_articles])\n",
        "\n",
        "    # call functions requested by the model\n",
        "    answer = args_resp.content\n",
        "    title_list = []\n",
        "    if args_resp.function_call:\n",
        "        # GPT inference again with calling external function\n",
        "        get_articles_prompt = \"\"\"\n",
        "            You are an assistant that provides news and headlines to user requests.\n",
        "            Always try to get the articles using the available function calls.\n",
        "            Write the arguments to your function at the top of your answer.\n",
        "            Please output something like this:\n",
        "            Number. [Title](Article Link)\\n\n",
        "                - Description: description\\n\n",
        "                - Publish Date: publish date\\n\n",
        "        \"\"\"\n",
        "        answer = gpt_client.request_with_function_call(\n",
        "            messages=messages,\n",
        "            function=news_api_client.get_articles,\n",
        "            function_call_resp=args_resp,\n",
        "            prompt=get_articles_prompt,\n",
        "        )\n",
        "\n",
        "    chat_history.append((prompt, answer))\n",
        "    return \"\", chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNcwR7o1tuGS"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        ## Chat\n",
        "        얻고 싶은 정보에 대해 질문해보세요.\n",
        "        \"\"\"\n",
        "    )\n",
        "    chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "    prompt = gr.Textbox(label=\"Input prompt\")\n",
        "    clear = gr.ClearButton([prompt, chatbot])\n",
        "\n",
        "    prompt.submit(respond, [prompt, chatbot], [prompt, chatbot])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwgIBbz3tuGS"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9svtqKLBtuGS"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3yayhoStuGS"
      },
      "source": [
        "## 뉴스 기사 요약 및 번역 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kCsZkL6tuGS"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Chat\n",
        "                얻고 싶은 정보에 대해 질문해보세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "            prompt = gr.Textbox(label=\"Input prompt\")\n",
        "            clear = gr.ClearButton([prompt, chatbot])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Select News article\n",
        "                원하는 기사를 선택하세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            article_list = gr.Dropdown(label=\"Article List\", choices=None)\n",
        "            abstract_box = gr.Textbox(\n",
        "                label=\"Summarized article\", lines=10, interactive=False\n",
        "            )\n",
        "            translate_box = gr.Textbox(\n",
        "                label=\"Translated article\", lines=10, interactive=False\n",
        "            )\n",
        "            crawl_btn = gr.Button(\"Get article!\")\n",
        "\n",
        "    prompt.submit(respond, [prompt, chatbot], [prompt, chatbot, article_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9bfmtfItuGS"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjUSFuEhtuGS"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FbK8M6jtuGS"
      },
      "source": [
        "## 뉴스 제목 리스트를 선택 기능 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJDNFYJ0tuGT"
      },
      "outputs": [],
      "source": [
        "signature_get_title_and_url = {\n",
        "    \"name\": \"get_title_and_url\",\n",
        "    \"description\": \"Get title of article and url.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"title\": {\n",
        "                \"type\": \"array\",\n",
        "                \"description\": \"title array of articles\",\n",
        "                \"items\": {\"type\": \"string\", \"description\": \"title of article\"},\n",
        "            },\n",
        "            \"url\": {\n",
        "                \"type\": \"array\",\n",
        "                \"description\": \"url array of articles\",\n",
        "                \"items\": {\"type\": \"string\", \"description\": \"url of article\"},\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"title\", \"url\"],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "323vgyHDtuGT"
      },
      "outputs": [],
      "source": [
        "TITLE_TO_URL = {}\n",
        "\n",
        "def respond(prompt: str, chat_history: List[str]) -> Tuple[str, List[str]]:\n",
        "    global TITLE_TO_URL\n",
        "\n",
        "    # Get args from prompt\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    args_resp = gpt_client.get_args_for_function_call(messages, [signature_get_articles])\n",
        "\n",
        "    # call functions requested by the model\n",
        "    answer = args_resp.content\n",
        "    title_list = []\n",
        "    if args_resp.function_call:\n",
        "        # GPT inference again with calling external function\n",
        "        get_articles_prompt = \"\"\"\n",
        "            You are an assistant that provides news and headlines to user requests.\n",
        "            Always try to get the articles using the available function calls.\n",
        "            Write the arguments to your function at the top of your answer.\n",
        "            Please output something like this:\n",
        "            Number. [Title](Article Link)\\n\n",
        "                - Description: description\\n\n",
        "                - Publish Date: publish date\\n\n",
        "        \"\"\"\n",
        "        answer = gpt_client.request_with_function_call(\n",
        "            messages=messages,\n",
        "            function=news_api_client.get_articles,\n",
        "            function_call_resp=args_resp,\n",
        "            prompt=get_articles_prompt,\n",
        "        )\n",
        "\n",
        "        # Get titles and urls for dropdown from response message\n",
        "        messages = [{\"role\": \"user\", \"content\": answer}]\n",
        "        args_resp = gpt_client.get_args_for_function_call(\n",
        "            messages, [signature_get_title_and_url]\n",
        "        )\n",
        "        args = json.loads(args_resp.function_call.arguments)\n",
        "        title_list, url_list = args.get(\"title\"), args.get(\"url\")\n",
        "        TITLE_TO_URL = {title: url for title, url in zip(title_list, url_list)}\n",
        "\n",
        "    chat_history.append((prompt, answer))\n",
        "\n",
        "    # Update dropdown\n",
        "    drop_down = None\n",
        "    if title_list:\n",
        "        drop_down = gr.update(choices=title_list, interactive=True)\n",
        "\n",
        "    return \"\", chat_history, drop_down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh47Wg1UtuGT"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Chat\n",
        "                얻고 싶은 정보에 대해 질문해보세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "            prompt = gr.Textbox(label=\"Input prompt\")\n",
        "            clear = gr.ClearButton([prompt, chatbot])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Select News article\n",
        "                원하는 기사를 선택하세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            article_list = gr.Dropdown(label=\"Article List\", choices=None)\n",
        "            abstract_box = gr.Textbox(\n",
        "                label=\"Summarized article\", lines=10, interactive=False\n",
        "            )\n",
        "            translate_box = gr.Textbox(\n",
        "                label=\"Translated article\", lines=10, interactive=False\n",
        "            )\n",
        "            scrap_btn = gr.Button(\"Get article!\")\n",
        "\n",
        "    prompt.submit(respond, [prompt, chatbot], [prompt, chatbot, article_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3w2Qxn5tuGT"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvuOATs_tuGT"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72blquNutuGT"
      },
      "source": [
        "## 뉴스 기사 스크래핑하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE2_XxGStuGT"
      },
      "outputs": [],
      "source": [
        "def scrap_cnn_article(url: str) -> Tuple[str, str]:\n",
        "    \"\"\"Scrap CNN news article.\"\"\"\n",
        "    rep = requests.get(url)\n",
        "\n",
        "    soup = BeautifulSoup(rep.content, \"html.parser\")\n",
        "\n",
        "    # Get main contents\n",
        "    article = \"\"\n",
        "    for paragraph in soup.find_all([\"p\", \"h2\"], {\"class\": [\"paragraph\", \"subheader\"]}):\n",
        "        article += paragraph.text.strip()\n",
        "\n",
        "    return article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIDusT8BtuGU"
      },
      "outputs": [],
      "source": [
        "article = scrap_cnn_article(\"https://edition.cnn.com/2023/09/07/us/caste-discrimination-bill-california-passes-cec/index.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsv5L3kXtuGU"
      },
      "outputs": [],
      "source": [
        "article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM0X-awMtuGU"
      },
      "source": [
        "## 뉴스 기사 요약 및 번역 기능 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMtIKPEItuGU"
      },
      "outputs": [],
      "source": [
        "class GPTClient:\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "        self.model = \"gpt-3.5-turbo\"\n",
        "\n",
        "    def get_args_for_function_call(\n",
        "        self, messages: List[Dict[str, str]], function_signatures: List[Dict[str, Any]]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        If there is information for function in messages, get argument from messages.\n",
        "        Otherwise get simple GPT response.\n",
        "        \"\"\"\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            functions=function_signatures,\n",
        "        )\n",
        "        return response.choices[0].message\n",
        "\n",
        "    def request_with_function_call(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        function: Callable,\n",
        "        function_call_resp,\n",
        "        prompt: str = \"\",\n",
        "    ) -> str:\n",
        "        function_name = function_call_resp.function_call.name\n",
        "\n",
        "        if prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": prompt})\n",
        "\n",
        "        # Run external function\n",
        "        kwargs = json.loads(function_call_resp.function_call.arguments)\n",
        "        function_result = function(**kwargs)\n",
        "\n",
        "        # Append message\n",
        "        messages.append(function_call_resp)\n",
        "        messages.append(\n",
        "            {\"role\": \"function\", \"name\": function_name, \"content\": function_result}\n",
        "        )\n",
        "\n",
        "        # GPT inference include function result\n",
        "        res = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "        )\n",
        "        return res.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize(self, texts: str) -> str:\n",
        "        prompt = f\"\"\"\n",
        "            Summarize the sentences '---' below.\n",
        "            ---\n",
        "            {texts}\n",
        "            \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "\n",
        "        # ChatGPT API 호출하기\n",
        "        response = self.client.chat.completions.create(model=self.model, messages=messages)\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def translate(self, texts: str) -> str:\n",
        "        prompt = f\"\"\"\n",
        "            Translate the sentences '---' below to Korean.\n",
        "            ---\n",
        "            {texts}\n",
        "            \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "\n",
        "        # ChatGPT API 호출하기\n",
        "        response = self.client.chat.completions.create(model=self.model, messages=messages)\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "gpt_client = GPTClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjRqKfGbtuGU"
      },
      "outputs": [],
      "source": [
        "def scrap_cnn_article(title: str) -> Tuple[str, str]:\n",
        "    url = TITLE_TO_URL[title]\n",
        "    rep = requests.get(url)\n",
        "\n",
        "    soup = BeautifulSoup(rep.content, \"html.parser\")\n",
        "\n",
        "    # Get main contents\n",
        "    article = \"\"\n",
        "    for paragraph in soup.find_all([\"p\", \"h2\"], {\"class\": [\"paragraph\", \"subheader\"]}):\n",
        "        article += paragraph.text.strip()\n",
        "\n",
        "    # Summarize and translate to Korean\n",
        "    summarized_article = gpt_client.summarize(article)\n",
        "    translated_article = gpt_client.translate(summarized_article)\n",
        "\n",
        "    return summarized_article, translated_article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw8cHF2etuGU"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Chat\n",
        "                얻고 싶은 정보에 대해 질문해보세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "            prompt = gr.Textbox(label=\"Input prompt\")\n",
        "            clear = gr.ClearButton([prompt, chatbot])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Select News article\n",
        "                원하는 기사를 선택하세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            article_list = gr.Dropdown(label=\"Article List\", choices=None)\n",
        "            abstract_box = gr.Textbox(\n",
        "                label=\"Summarized article\", lines=10, interactive=False\n",
        "            )\n",
        "            translate_box = gr.Textbox(\n",
        "                label=\"Translated article\", lines=10, interactive=False\n",
        "            )\n",
        "            scrap_btn = gr.Button(\"Get article!\")\n",
        "\n",
        "    prompt.submit(respond, [prompt, chatbot], [prompt, chatbot, article_list])\n",
        "    scrap_btn.click(\n",
        "        scrap_cnn_article, inputs=[article_list], outputs=[abstract_box, translate_box]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tikg6fOjtuGU"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCrNy5KQtuGU"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mROM9wbtuGU"
      },
      "source": [
        "## 최종 App 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N03jNmcDtuGU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Any, Callable, Dict, List, Tuple\n",
        "\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFfDp_14tuGU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\"\n",
        "os.environ[\"NEWS_API_KEY\"] = \"<NEWS_API_KEY>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVmP-lTqtuGU"
      },
      "outputs": [],
      "source": [
        "class GPTClient:\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "        self.model = \"gpt-3.5-turbo\"\n",
        "\n",
        "    def get_args_for_function_call(\n",
        "        self, messages: List[Dict[str, str]], function_signatures: List[Dict[str, Any]]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        If there is information for function in messages, get argument from messages.\n",
        "        Otherwise get simple GPT response.\n",
        "        \"\"\"\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            functions=function_signatures,\n",
        "        )\n",
        "        return response.choices[0].message\n",
        "\n",
        "    def request_with_function_call(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        function: Callable,\n",
        "        function_call_resp,\n",
        "        prompt: str = \"\",\n",
        "    ) -> str:\n",
        "        function_name = function_call_resp.function_call.name\n",
        "\n",
        "        if prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": prompt})\n",
        "\n",
        "        # Run external function\n",
        "        kwargs = json.loads(function_call_resp.function_call.arguments)\n",
        "        function_result = function(**kwargs)\n",
        "\n",
        "        # Append message\n",
        "        messages.append(function_call_resp)\n",
        "        messages.append(\n",
        "            {\"role\": \"function\", \"name\": function_name, \"content\": function_result}\n",
        "        )\n",
        "\n",
        "        # GPT inference include function result\n",
        "        res = openai.ChatCompletion.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "        )\n",
        "        return res.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize(self, texts: str) -> str:\n",
        "        prompt = f\"\"\"\n",
        "            Summarize the sentences '---' below.\n",
        "            ---\n",
        "            {texts}\n",
        "            \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "\n",
        "        # ChatGPT API 호출하기\n",
        "        response = self.client.chat.completions.create(model=self.model, messages=messages)\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def translate(self, texts: str) -> str:\n",
        "        prompt = f\"\"\"\n",
        "            Translate the sentences '---' below to Korean.\n",
        "            ---\n",
        "            {texts}\n",
        "            \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "\n",
        "        # ChatGPT API 호출하기\n",
        "        response = self.client.chat.completions.create(model=self.model, messages=messages)\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "gpt_client = GPTClient()\n",
        "\n",
        "\n",
        "class NewsApiClient:\n",
        "    def __init__(self):\n",
        "        self.news_api_key = os.environ[\"NEWS_API_KEY\"]\n",
        "        self.max_num_articles = 5\n",
        "\n",
        "    def get_articles(\n",
        "        self,\n",
        "        query: str = None,\n",
        "        from_date: str = None,\n",
        "        to_date: str = None,\n",
        "        sort_by: str = None,\n",
        "    ) -> str:\n",
        "        \"\"\"Retrieve articles from newsapi.org (API key required)\"\"\"\n",
        "        base_url = \"https://newsapi.org/v2/everything\"\n",
        "        headers = {\"x-api-key\": self.news_api_key}\n",
        "        params = {\n",
        "            \"sortBy\": \"publishedAt\",\n",
        "            \"sources\": \"cnn\",\n",
        "            \"language\": \"en\",\n",
        "        }\n",
        "\n",
        "        if query is not None:\n",
        "            params[\"q\"] = query\n",
        "        if from_date is not None:\n",
        "            params[\"from\"] = from_date\n",
        "        if to_date is not None:\n",
        "            params[\"to\"] = to_date\n",
        "        if sort_by is not None:\n",
        "            params[\"sortBy\"] = sort_by\n",
        "\n",
        "        # Fetch from newsapi.org\n",
        "        # reference: https://newsapi.org/docs/endpoints/top-headlines\n",
        "        response = requests.get(base_url, params=params, headers=headers)\n",
        "        data = response.json()\n",
        "\n",
        "        if data[\"status\"] == \"ok\":\n",
        "            print(\n",
        "                f\"Processing {data['totalResults']} articles from newsapi.org. \"\n",
        "                + f\"Max number is {self.max_num_articles}.\"\n",
        "            )\n",
        "            return json.dumps(\n",
        "                data[\"articles\"][: min(self.max_num_articles, len(data[\"articles\"]))]\n",
        "            )\n",
        "        else:\n",
        "            print(\"Request failed with message:\", data[\"message\"])\n",
        "            return \"No articles found\"\n",
        "\n",
        "\n",
        "news_api_client = NewsApiClient()\n",
        "gpt_client = GPTClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNKZ2wzltuGU"
      },
      "outputs": [],
      "source": [
        "def scrap_cnn_article(title: str) -> Tuple[str, str]:\n",
        "    url = TITLE_TO_URL[title]\n",
        "    rep = requests.get(url)\n",
        "\n",
        "    soup = BeautifulSoup(rep.content, \"html.parser\")\n",
        "\n",
        "    # Get main contents\n",
        "    article = \"\"\n",
        "    for paragraph in soup.find_all([\"p\", \"h2\"], {\"class\": [\"paragraph\", \"subheader\"]}):\n",
        "        article += paragraph.text.strip()\n",
        "\n",
        "    # Summarize and translate to Korean\n",
        "    summarized_article = gpt_client.summarize(article)\n",
        "    translated_article = gpt_client.translate(summarized_article)\n",
        "\n",
        "    return summarized_article, translated_article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nazh0AZotuGU"
      },
      "outputs": [],
      "source": [
        "signature_get_articles = {\n",
        "    \"name\": \"get_articles\",\n",
        "    \"description\": \"Get news articles\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Freeform keywords or a phrase to search for.\",\n",
        "            },\n",
        "            \"from_date\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A date and optional time for the oldest article allowed. This should be in ISO 8601 format\",\n",
        "            },\n",
        "            \"to_date\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A date and optional time for the newest article allowed. This should be in ISO 8601 format\",\n",
        "            },\n",
        "            \"sort_by\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The order to sort the articles in\",\n",
        "                \"enum\": [\"relevancy\", \"popularity\", \"publishedAt\"],\n",
        "            },\n",
        "        },\n",
        "        \"required\": [],\n",
        "    },\n",
        "}\n",
        "\n",
        "signature_get_title_and_url = {\n",
        "    \"name\": \"get_title_and_url\",\n",
        "    \"description\": \"Get title of article and url.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"title\": {\n",
        "                \"type\": \"array\",\n",
        "                \"description\": \"title array of articles\",\n",
        "                \"items\": {\"type\": \"string\", \"description\": \"title of article\"},\n",
        "            },\n",
        "            \"url\": {\n",
        "                \"type\": \"array\",\n",
        "                \"description\": \"url array of articles\",\n",
        "                \"items\": {\"type\": \"string\", \"description\": \"url of article\"},\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"title\", \"url\"],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-f4ixs5tuGV"
      },
      "outputs": [],
      "source": [
        "TITLE_TO_URL = {}\n",
        "\n",
        "def respond(prompt: str, chat_history: List[str]) -> Tuple[str, List[str]]:\n",
        "    global TITLE_TO_URL\n",
        "\n",
        "    # Get args from prompt\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    args_resp = gpt_client.get_args_for_function_call(messages, [signature_get_articles])\n",
        "\n",
        "    # call functions requested by the model\n",
        "    answer = args_resp.content\n",
        "    title_list = []\n",
        "    if args_resp.function_call:\n",
        "        # GPT inference again with calling external function\n",
        "        get_articles_prompt = \"\"\"\n",
        "            You are an assistant that provides news and headlines to user requests.\n",
        "            Always try to get the articles using the available function calls.\n",
        "            Write the arguments to your function at the top of your answer.\n",
        "            Please output something like this:\n",
        "            Number. [Title](Article Link)\\n\n",
        "                - Description: description\\n\n",
        "                - Publish Date: publish date\\n\n",
        "        \"\"\"\n",
        "        answer = gpt_client.request_with_function_call(\n",
        "            messages=messages,\n",
        "            function=news_api_client.get_articles,\n",
        "            function_call_resp=args_resp,\n",
        "            prompt=get_articles_prompt,\n",
        "        )\n",
        "\n",
        "        # Get titles and urls for dropdown from response message\n",
        "        messages = [{\"role\": \"user\", \"content\": answer}]\n",
        "        args_resp = gpt_client.get_args_for_function_call(\n",
        "            messages, [signature_get_title_and_url]\n",
        "        )\n",
        "        args = json.loads(args_resp.function_call.arguments)\n",
        "        title_list, url_list = args.get(\"title\"), args.get(\"url\")\n",
        "        TITLE_TO_URL = {title: url for title, url in zip(title_list, url_list)}\n",
        "\n",
        "    chat_history.append((prompt, answer))\n",
        "\n",
        "    # Update dropdown\n",
        "    drop_down = None\n",
        "    if title_list:\n",
        "        drop_down = gr.update(choices=title_list, interactive=True)\n",
        "\n",
        "    return \"\", chat_history, drop_down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLWedz4StuGV"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 뉴스 기사 탐색 챗봇\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Chat\n",
        "                얻고 싶은 정보에 대해 질문해보세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            chatbot = gr.Chatbot(label=\"Chat History\")\n",
        "            prompt = gr.Textbox(label=\"Input prompt\")\n",
        "            clear = gr.ClearButton([prompt, chatbot])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ## Select News article\n",
        "                원하는 기사를 선택하세요.\n",
        "                \"\"\"\n",
        "            )\n",
        "            article_list = gr.Dropdown(label=\"Article List\", choices=None)\n",
        "            abstract_box = gr.Textbox(\n",
        "                label=\"Summarized article\", lines=10, interactive=False\n",
        "            )\n",
        "            translate_box = gr.Textbox(\n",
        "                label=\"Translated article\", lines=10, interactive=False\n",
        "            )\n",
        "            scrap_btn = gr.Button(\"Get article!\")\n",
        "\n",
        "    prompt.submit(respond, [prompt, chatbot], [prompt, chatbot, article_list])\n",
        "    scrap_btn.click(\n",
        "        scrap_cnn_article, inputs=[article_list], outputs=[abstract_box, translate_box]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3GGT94ktuGV"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUCKVcKdtuGV"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl_apps",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}