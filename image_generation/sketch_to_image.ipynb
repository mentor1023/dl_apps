{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUv0oLobvCKp"
      },
      "source": [
        "# Sketch to Image Application\n",
        "\n",
        "Colab 환경에서 스케치 투 이미지 애플리케이션을 만들어봅시다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxIxrPMYvPr1"
      },
      "source": [
        "## 패키지 및 예제 데이터 다운로드하기\n",
        "python package들을 설치합니다. Colab에서 실행하지 않는 경우 이 셀은 실행하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CiswP_Ef97e"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mentor1023/dl_apps/main/image_generation/requirements-colab.txt\n",
        "!pip install -r requirements-colab.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mentor1023/dl_apps/main/image_generation/requirements-colab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsphRZWmi0Uy",
        "outputId": "7cf2ffa8-472e-46ad-cdca-bea9aa9d13ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-15 13:39:39--  https://raw.githubusercontent.com/mentor1023/dl_apps/main/image_generation/requirements-colab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59 [text/plain]\n",
            "Saving to: ‘requirements-colab.txt’\n",
            "\n",
            "requirements-colab. 100%[===================>]      59  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-15 13:39:40 (1.42 MB/s) - ‘requirements-colab.txt’ saved [59/59]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-colab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRaSmnkIi0K2",
        "outputId": "f89975d2-5430-4f8c-f3bc-41f3ae6010af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers==0.26.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 1)) (0.26.2)\n",
            "Requirement already satisfied: accelerate==0.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 2)) (0.31.0)\n",
            "Requirement already satisfied: gradio==3.40.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 5)) (3.40.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (0.24.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.2->-r requirements-colab.txt (line 1)) (10.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.31.0->-r requirements-colab.txt (line 2)) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (23.2.1)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.11.10)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: gradio-client>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.3.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.10.12)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.0.19)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.34.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 5)) (11.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.4.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.31.0->-r requirements-colab.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.31.0->-r requirements-colab.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.31.0->-r requirements-colab.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.41.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.26.2->-r requirements-colab.txt (line 1)) (3.21.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (0.22.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.40.0->-r requirements-colab.txt (line 5)) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQzhGixSS7eC"
      },
      "source": [
        "## 패키지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub==0.24.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwK-XakTj062",
        "outputId": "e1b7bd57-4641-4ffb-c45b-e789719d955b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub==0.24.7 in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.7) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.7) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.7) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.7) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4IljnAX2KlAz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import IO\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa8lhoPRKu-G"
      },
      "source": [
        "## 스케치 투 이미지 생성 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mpG7E21tkSnk"
      },
      "outputs": [],
      "source": [
        "WIDTH = 512\n",
        "HEIGHT = 512\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## 프롬프트 입력\")\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(label=\"Prompt\")\n",
        "    with gr.Row():\n",
        "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
        "\n",
        "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Tab(\"Canvas\"):\n",
        "                with gr.Row():\n",
        "                    canvas = gr.Image(\n",
        "                        label=\"Draw\",\n",
        "                        source=\"canvas\",\n",
        "                        image_mode=\"RGB\",\n",
        "                        tool=\"color-sketch\",\n",
        "                        interactive=True,\n",
        "                        width=WIDTH,\n",
        "                        height=HEIGHT,\n",
        "                        shape=(WIDTH, HEIGHT),\n",
        "                        brush_radius=20,\n",
        "                        type=\"pil\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
        "\n",
        "            with gr.Tab(\"File\"):\n",
        "                with gr.Row():\n",
        "                    file = gr.Image(\n",
        "                        label=\"Upload\",\n",
        "                        source=\"upload\",\n",
        "                        image_mode=\"RGB\",\n",
        "                        tool=\"color-sketch\",\n",
        "                        interactive=True,\n",
        "                        width=WIDTH,\n",
        "                        height=HEIGHT,\n",
        "                        shape=(WIDTH, HEIGHT),\n",
        "                        type=\"pil\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    file_run_btn = gr.Button(value=\"Generate\")\n",
        "\n",
        "        with gr.Column():\n",
        "            result_gallery = gr.Gallery(label=\"Output\", height=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BJiCOxqWkm-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a3467d-fcda-4784-8f97-bb666f76a08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://bd0a51d1188db120e7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CFQdzntYkolK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad90b454-1b70-44af-c5fc-9ede78c83034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiop_vbXkqeZ"
      },
      "source": [
        "## 모델 다운로드 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDzXlEk08KB3"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## 모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_url = gr.Textbox(label=\"모델 URL\", placeholder=\"https://civitai.com/\")\n",
        "        download_model_btn = gr.Button(value=\"모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_file = gr.File(label=\"모델 파일\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g57Gecpx-43U"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJYBR55T-6Zn"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFftn_M6AaPL"
      },
      "source": [
        "## 모델 다운로드 기능 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "iyNLhdrYqu76"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-N5CvL0CQXFp"
      },
      "outputs": [],
      "source": [
        "def download_model(url: str) -> str:\n",
        "    print(\"---------- start -------------\")\n",
        "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
        "\n",
        "    try:\n",
        "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout=600)\n",
        "    except Exception as err:\n",
        "        print(f\"[ERROR] {err}\")\n",
        "        raise err\n",
        "\n",
        "    download_url = response.json()[\"modelVersions\"][0][\"downloadUrl\"]\n",
        "    filename = response.json()[\"modelVersions\"][0][\"files\"][0][\"name\"]\n",
        "\n",
        "    file_path = f\"models/{filename}\"\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"[INFO] File already exists: {file_path}\")\n",
        "        return file_path\n",
        "\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    print(\"---------- end -------------\")\n",
        "\n",
        "    download_from_url(download_url, file_path)\n",
        "    print(f\"[INFO] File downloaded: {file_path}\")\n",
        "\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def download_from_url(url: str, file_path: str, chunk_size: int = 1024):\n",
        "    print(\"---------- start 2 -------------\")\n",
        "    resp = requests.get(url, stream=True)\n",
        "    total = int(resp.headers.get('content-length', 0))\n",
        "    with open(file_path, 'wb') as file, tqdm(\n",
        "        desc=file_path,\n",
        "        total=total,\n",
        "        unit='iB',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in resp.iter_content(chunk_size=chunk_size):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)\n",
        "    print(\"---------- end 1 -------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "U0IbkRIcRD-b"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## 모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_url = gr.Textbox(label=\"모델 URL\", placeholder=\"https://civitai.com/\")\n",
        "        download_model_btn = gr.Button(value=\"모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_file = gr.File(label=\"모델 파일\")\n",
        "\n",
        "    download_model_btn.click(\n",
        "        download_model,\n",
        "        [model_url],\n",
        "        [model_file],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vz1-B1ZTTUKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a8926c-3227-4e24-b71a-eebf3b4fd403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4fac1eaaa88a7e32db.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "app.queue().launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "xQ3DdaUeTVfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2001d273-46f8-46d6-cff8-d3b75b751c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO3V8z6-QX__"
      },
      "source": [
        "## 모델 불러오기 UI 및 기능 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDX0T6-jA7DF"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## 모델 불러오기\")\n",
        "    with gr.Row():\n",
        "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
        "    with gr.Row():\n",
        "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4Tb3Ly_PogVu"
      },
      "outputs": [],
      "source": [
        "PIPELINE = None\n",
        "\n",
        "def init_pipeline(model_file: IO) -> str:\n",
        "    print(\"[INFO] Initialize pipeline\")\n",
        "    global PIPELINE\n",
        "    PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
        "        model_file.name,\n",
        "        torch_dtype=torch.float16,\n",
        "        variant=\"fp16\",\n",
        "        use_safetensors=True,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    print(\"[INFO] Initialized pipeline\")\n",
        "    return \"Model Loaded!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RcxCcRYCsuxr"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## 모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_url = gr.Textbox(label=\"모델 URL\", placeholder=\"https://civitai.com/\")\n",
        "        download_model_btn = gr.Button(value=\"모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_file = gr.File(label=\"모델 파일\")\n",
        "\n",
        "    gr.Markdown(\"## 모델 불러오기\")\n",
        "    with gr.Row():\n",
        "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
        "    with gr.Row():\n",
        "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
        "\n",
        "    download_model_btn.click(\n",
        "        download_model,\n",
        "        [model_url],\n",
        "        [model_file],\n",
        "    )\n",
        "    load_model_btn.click(\n",
        "        init_pipeline,\n",
        "        [model_file],\n",
        "        [is_model_check],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kfUumDF3A-IN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df82a93a-c829-4c96-90e4-c4b9c0b547c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://3c5913f13ea1b779ae.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "app.queue().launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8bKanmd2A-lB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7980790-6170-4f23-9fff-297a48350f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo8u_NmL-Q2_"
      },
      "source": [
        "## 스케치 투 이미지 생성 기능 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PmF6CY38-hdx"
      },
      "outputs": [],
      "source": [
        "def sketch_to_image(sketch: Image.Image, prompt: str, negative_prompt: str):\n",
        "    width, height = sketch.size\n",
        "    images =  PIPELINE(\n",
        "        image=sketch,\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        num_images_per_prompt=4,\n",
        "        num_inference_steps=20,\n",
        "        strength=0.7,\n",
        "    ).images\n",
        "\n",
        "    with torch.cuda.device(\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MhtyymPnAaPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857af1bb-b977-4182-ef96-6caccb6d600c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Gradio app ready\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] Gradio app ready\")\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 스케치 to 이미지 애플리케이션\")\n",
        "\n",
        "    gr.Markdown(\"## 모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_url = gr.Textbox(label=\"Model Link\", placeholder=\"https://civitai.com/\")\n",
        "        download_model_btn = gr.Button(value=\"Download model\")\n",
        "    with gr.Row():\n",
        "        model_file = gr.File(label=\"Model File\")\n",
        "\n",
        "    gr.Markdown(\"## 모델 불러오기\")\n",
        "    with gr.Row():\n",
        "        load_model_btn = gr.Button(value=\"Load model\")\n",
        "    with gr.Row():\n",
        "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not loaded\")\n",
        "\n",
        "    gr.Markdown(\"## 프롬프트 입력\")\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(label=\"Prompt\")\n",
        "    with gr.Row():\n",
        "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
        "\n",
        "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Tab(\"Canvas\"):\n",
        "                with gr.Row():\n",
        "                    canvas = gr.Image(\n",
        "                        label=\"Draw\",\n",
        "                        source=\"canvas\",\n",
        "                        image_mode=\"RGB\",\n",
        "                        tool=\"color-sketch\",\n",
        "                        interactive=True,\n",
        "                        width=WIDTH,\n",
        "                        height=HEIGHT,\n",
        "                        shape=(WIDTH, HEIGHT),\n",
        "                        brush_radius=20,\n",
        "                        type=\"pil\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
        "\n",
        "            with gr.Tab(\"File\"):\n",
        "                with gr.Row():\n",
        "                    file = gr.Image(\n",
        "                        label=\"Upload\",\n",
        "                        source=\"upload\",\n",
        "                        image_mode=\"RGB\",\n",
        "                        tool=\"color-sketch\",\n",
        "                        interactive=True,\n",
        "                        width=WIDTH,\n",
        "                        height=HEIGHT,\n",
        "                        shape=(WIDTH, HEIGHT),\n",
        "                        type=\"pil\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    file_run_btn = gr.Button(value=\"Generate\")\n",
        "\n",
        "        with gr.Column():\n",
        "            result_gallery = gr.Gallery(label=\"Output\", height=512)\n",
        "\n",
        "\n",
        "    # Event\n",
        "    download_model_btn.click(\n",
        "        download_model,\n",
        "        [model_url],\n",
        "        [model_file],\n",
        "    )\n",
        "    load_model_btn.click(\n",
        "        init_pipeline,\n",
        "        [model_file],\n",
        "        [is_model_check],\n",
        "    )\n",
        "    canvas_run_btn.click(\n",
        "        sketch_to_image,\n",
        "        [canvas, prompt, n_prompt],\n",
        "        [result_gallery],\n",
        "    )\n",
        "    file_run_btn.click(\n",
        "        sketch_to_image,\n",
        "        [file, prompt, n_prompt],\n",
        "        [result_gallery],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KsZPfHyHAaPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1620fd12-3f1a-46f5-8dcd-4b98fdf09108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c094fe97f48ed6bc22.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "app.queue().launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UAOZlzKoAaPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159bcff6-62fb-47bb-cd8a-5b1319475cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del download_model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1EZZzAyhoN8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmZOiRmXAIGs"
      },
      "source": [
        "## 최종 App 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3OGnSU94Ky37"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import IO\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_EJHWMdOHh2G"
      },
      "outputs": [],
      "source": [
        "WIDTH = 512\n",
        "HEIGHT = 512\n",
        "\n",
        "PIPELINE = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "roRHRyqRBTqX"
      },
      "outputs": [],
      "source": [
        "def download_model(url: str) -> str:\n",
        "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
        "\n",
        "    try:\n",
        "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout=600)\n",
        "    except Exception as err:\n",
        "        print(f\"[ERROR] {err}\")\n",
        "        raise err\n",
        "\n",
        "    download_url = response.json()[\"modelVersions\"][0][\"downloadUrl\"]\n",
        "    filename = response.json()[\"modelVersions\"][0][\"files\"][0][\"name\"]\n",
        "\n",
        "    file_path = f\"models/{filename}\"\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"[INFO] File already exists: {file_path}\")\n",
        "        return file_path\n",
        "\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    download_from_url(download_url, file_path)\n",
        "    print(f\"[INFO] File downloaded: {file_path}\")\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def download_from_url(url: str, file_path: str, chunk_size=1024):\n",
        "    resp = requests.get(url, stream=True)\n",
        "    total = int(resp.headers.get('content-length', 0))\n",
        "    with open(file_path, 'wb') as file, tqdm(\n",
        "        desc=file_path,\n",
        "        total=total,\n",
        "        unit='iB',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in resp.iter_content(chunk_size=chunk_size):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)\n",
        "\n",
        "\n",
        "def init_pipeline(model_file: IO) -> str:\n",
        "    print(\"[INFO] Initialize pipeline\")\n",
        "    global PIPELINE\n",
        "    PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
        "        model_file.name,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "    ).to(\"cuda\")\n",
        "    print(\"[INFO] Initialized pipeline\")\n",
        "    return \"Model Loaded!\"\n",
        "\n",
        "\n",
        "def sketch_to_image(sketch: Image.Image, prompt: str, negative_prompt: str):\n",
        "    width, height = sketch.size\n",
        "    return PIPELINE(\n",
        "        image=sketch,\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        num_images_per_prompt=4,\n",
        "        num_inference_steps=20,\n",
        "        strength=0.7,\n",
        "    ).images\n",
        "\n",
        "    with torch.cuda.device(\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QcAEk-3kcnEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d42859a-21f0-4da3-bb3d-cc49d24afefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Gradio app ready\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] Gradio app ready\")\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 스케치 to 이미지 애플리케이션\")\n",
        "\n",
        "    gr.Markdown(\"## 모델 다운로드\")\n",
        "    with gr.Row():\n",
        "        model_url = gr.Textbox(label=\"Model Link\", placeholder=\"https://civitai.com/\")\n",
        "        download_model_btn = gr.Button(value=\"Download model\")\n",
        "    with gr.Row():\n",
        "        model_file = gr.File(label=\"Model File\")\n",
        "\n",
        "    gr.Markdown(\"## 모델 불러오기\")\n",
        "    with gr.Row():\n",
        "        load_model_btn = gr.Button(value=\"Load model\")\n",
        "    with gr.Row():\n",
        "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not loaded\")\n",
        "\n",
        "    gr.Markdown(\"## 프롬프트 입력\")\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(label=\"Prompt\")\n",
        "    with gr.Row():\n",
        "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
        "\n",
        "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Tab(\"Canvas\"):\n",
        "                with gr.Row():\n",
        "                    canvas = gr.Image(\n",
        "                        label=\"Draw\",\n",
        "                        source=\"canvas\",\n",
        "                        image_mode=\"RGB\",\n",
        "                        tool=\"color-sketch\",\n",
        "                        interactive=True,\n",
        "                        width=WIDTH,\n",
        "                        height=HEIGHT,\n",
        "                        shape=(WIDTH, HEIGHT),\n",
        "                        brush_radius=20,\n",
        "                        type=\"pil\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    canvas_run_btn = gr.Button(value=\"Generate\")\n",
        "\n",
        "            with gr.Tab(\"File\"):\n",
        "                with gr.Row():\n",
        "                    file = gr.Image(\n",
        "                        label=\"Upload\",\n",
        "                        source=\"upload\",\n",
        "                        image_mode=\"RGB\",\n",
        "                        tool=\"color-sketch\",\n",
        "                        interactive=True,\n",
        "                        width=WIDTH,\n",
        "                        height=HEIGHT,\n",
        "                        shape=(WIDTH, HEIGHT),\n",
        "                        type=\"pil\",\n",
        "                    )\n",
        "                with gr.Row():\n",
        "                    file_run_btn = gr.Button(value=\"Generate\")\n",
        "\n",
        "        with gr.Column():\n",
        "            result_gallery = gr.Gallery(label=\"Output\", height=512)\n",
        "\n",
        "\n",
        "    # Event\n",
        "    download_model_btn.click(\n",
        "        download_model,\n",
        "        [model_url],\n",
        "        [model_file],\n",
        "    )\n",
        "    load_model_btn.click(\n",
        "        init_pipeline,\n",
        "        [model_file],\n",
        "        [is_model_check],\n",
        "    )\n",
        "    canvas_run_btn.click(\n",
        "        sketch_to_image,\n",
        "        [canvas, prompt, n_prompt],\n",
        "        [result_gallery],\n",
        "    )\n",
        "    file_run_btn.click(\n",
        "        sketch_to_image,\n",
        "        [file, prompt, n_prompt],\n",
        "        [result_gallery],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "aYqUda4T1LdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3c47c4-f40a-458f-b240-adfb26631770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0e8f5d30ebd0575e8c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "app.queue().launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM1HqDzu2KuF"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf9TcRItMH1l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}